{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string as str\n",
    "# import seaborn as sns\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pauln - Got my arse kicked at Crystal Palace -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>@IHeartLost yeah, it is pretty cool. I prefer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>I'm happy... Not for any real reason.. Just ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>slept very well.take a shower now.have to do m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>@GOttaviani yesss, it's cool, my favorite tune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79995</td>\n",
       "      <td>79995</td>\n",
       "      <td>4</td>\n",
       "      <td>raidys bbq tonight  free food &amp;amp; morrellis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79996</td>\n",
       "      <td>79996</td>\n",
       "      <td>4</td>\n",
       "      <td>Don't you just luv follow fridays--** thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79997</td>\n",
       "      <td>79997</td>\n",
       "      <td>4</td>\n",
       "      <td>@megodbike ahh I see! you need to go recruit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79998</td>\n",
       "      <td>79998</td>\n",
       "      <td>0</td>\n",
       "      <td>is not of housewife material : self-cooked ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79999</td>\n",
       "      <td>79999</td>\n",
       "      <td>0</td>\n",
       "      <td>Momma is sick  wish I could go see her</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  sentiment  \\\n",
       "0               0          0   \n",
       "1               1          4   \n",
       "2               2          4   \n",
       "3               3          0   \n",
       "4               4          4   \n",
       "...           ...        ...   \n",
       "79995       79995          4   \n",
       "79996       79996          4   \n",
       "79997       79997          4   \n",
       "79998       79998          0   \n",
       "79999       79999          0   \n",
       "\n",
       "                                                    text  \n",
       "0      pauln - Got my arse kicked at Crystal Palace -...  \n",
       "1      @IHeartLost yeah, it is pretty cool. I prefer ...  \n",
       "2      I'm happy... Not for any real reason.. Just ha...  \n",
       "3      slept very well.take a shower now.have to do m...  \n",
       "4      @GOttaviani yesss, it's cool, my favorite tune...  \n",
       "...                                                  ...  \n",
       "79995  raidys bbq tonight  free food &amp; morrellis ...  \n",
       "79996  Don't you just luv follow fridays--** thank yo...  \n",
       "79997  @megodbike ahh I see! you need to go recruit s...  \n",
       "79998  is not of housewife material : self-cooked ric...  \n",
       "79999             Momma is sick  wish I could go see her  \n",
       "\n",
       "[80000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"tweet_training.csv\")\n",
    "df_validation = pd.read_csv(\"tweet_dev.csv\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strips emojis\n",
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :'),:D, : D, =)\n",
    "    \n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))|:\\s?D | =\\)', '', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-: , :p\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)|:p', '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data with below components removed or replaced\n",
    "url = re.compile(r\"(?:(http[s]?://\\S+)|((//)?(\\w+\\.)?\\w+\\.\\w+/\\S+))\")\n",
    "user_mention = re.compile(r\"(?:(?<!\\w)@\\w+\\b)\")\n",
    "number = re.compile(r\"(?:\\b\\d+\\b)\")\n",
    "repeated_char = '([a-zA-Z])\\\\1+'\n",
    "length_repeated_char = '\\\\1\\\\1'\n",
    "\n",
    "def clean(raw):\n",
    "  #convert HTML encoding to text\n",
    "  new_row = BeautifulSoup(raw, 'html.parser').get_text()\n",
    "  \n",
    "  #Change all text to lower case\n",
    "  new_row = new_row.lower()\n",
    "  \n",
    "  #Replaces any url with class URL\n",
    "  new_row = re.sub(url, '', new_row)\n",
    "  \n",
    "  #replace any @username with class USERNAME\n",
    "  new_row = re.sub(user_mention, '', new_row)\n",
    "  \n",
    "  #Strips repeated chars\n",
    "  new_row = re.sub(repeated_char, length_repeated_char, new_row)\n",
    "  \n",
    "  #Replaces #hashtag with hashtag\n",
    "  new_row = re.sub(r'#(\\S+)', r' \\1 ', new_row)\n",
    "  \n",
    "  #Remove numbers\n",
    "  new_row = re.sub(number, '', new_row)\n",
    "  \n",
    "  #decode text with 'utf-8-sig'\n",
    "  try:\n",
    "    temp_row = new_row.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")     \n",
    "  except:\n",
    "    temp_row = new_row\n",
    "  \n",
    "  #Removes emojis\n",
    "  new_row = handle_emojis(temp_row);\n",
    "  \n",
    "  return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = []\n",
    "clean_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 80000):\n",
    "    clean_train.append(clean(df_train['text'][i]))\n",
    "\n",
    "for i in range(0, 16000):\n",
    "    clean_validation.append(clean(df_validation['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv file\n",
    "clean_df_train = pd.DataFrame(clean_train, columns=['text'])\n",
    "clean_df_validation = pd.DataFrame(clean_validation, columns = ['text'])\n",
    "\n",
    "clean_df_train['target'] = df_train.sentiment\n",
    "clean_df_validation['target'] = df_validation.sentiment\n",
    "\n",
    "clean_df_train.to_csv('tweet_clean_train.csv',encoding='utf-8')\n",
    "clean_df_validation.to_csv(\"tweet_clean_validation.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pauln - got my arse kicked at crystal palace -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>yeah, it is pretty cool. i prefer it when eve...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i'm happy... not for any real reason.. just ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>slept very well.take a shower now.have to do m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>yess, it's cool, my favorite tune in . intere...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79995</td>\n",
       "      <td>raidys bbq tonight  free food &amp; morrellis ice ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79996</td>\n",
       "      <td>don't you just luv follow fridays--** thank yo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79997</td>\n",
       "      <td>ahh i see! you need to go recruit some young ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79998</td>\n",
       "      <td>is not of housewife material : self-cooked ric...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79999</td>\n",
       "      <td>momma is sick  wish i could go see her</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      pauln - got my arse kicked at crystal palace -...       0\n",
       "1       yeah, it is pretty cool. i prefer it when eve...       4\n",
       "2      i'm happy... not for any real reason.. just ha...       4\n",
       "3      slept very well.take a shower now.have to do m...       0\n",
       "4       yess, it's cool, my favorite tune in . intere...       4\n",
       "...                                                  ...     ...\n",
       "79995  raidys bbq tonight  free food & morrellis ice ...       4\n",
       "79996  don't you just luv follow fridays--** thank yo...       4\n",
       "79997   ahh i see! you need to go recruit some young ...       4\n",
       "79998  is not of housewife material : self-cooked ric...       0\n",
       "79999             momma is sick  wish i could go see her       0\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using columns 1,2 because col 0 is the number of the row, could be changed if the row number is removed from the csv file.\n",
    "traindf = pd.read_csv('tweet_clean_train.csv', usecols = [1,2], encoding='latin-1')\n",
    "validationdf = pd.read_csv(\"tweet_clean_validation.csv\", usecols = [1,2], encoding = \"latin-1\")\n",
    "\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80000 entries, 0 to 79999\n",
      "Data columns (total 2 columns):\n",
      "text      80000 non-null object\n",
      "target    80000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pauln - got my arse kicked at crystal palace -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>yeah, it is pretty cool. i prefer it when ever...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i'm happy... not for any real reason.. just ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>slept very well.take a shower now.have to do m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>yess, it's cool, my favorite tune in . interes...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79995</td>\n",
       "      <td>raidys bbq tonight  free food &amp; morrellis ice ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79996</td>\n",
       "      <td>don't you just luv follow fridays--** thank yo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79997</td>\n",
       "      <td>ahh i see! you need to go recruit some young l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79998</td>\n",
       "      <td>is not of housewife material : self-cooked ric...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79999</td>\n",
       "      <td>momma is sick  wish i could go see her</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79846 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      pauln - got my arse kicked at crystal palace -...       0\n",
       "1      yeah, it is pretty cool. i prefer it when ever...       4\n",
       "2      i'm happy... not for any real reason.. just ha...       4\n",
       "3      slept very well.take a shower now.have to do m...       0\n",
       "4      yess, it's cool, my favorite tune in . interes...       4\n",
       "...                                                  ...     ...\n",
       "79995  raidys bbq tonight  free food & morrellis ice ...       4\n",
       "79996  don't you just luv follow fridays--** thank yo...       4\n",
       "79997  ahh i see! you need to go recruit some young l...       4\n",
       "79998  is not of housewife material : self-cooked ric...       0\n",
       "79999             momma is sick  wish i could go see her       0\n",
       "\n",
       "[79846 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking read cleaned file info if there are any null entries (found none) or white space\n",
    "traindf.info()\n",
    "traindf['text'] = traindf['text'].str.strip()\n",
    "traindf.drop(traindf[traindf.text == ''].index, inplace=True)\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = traindf[\"text\"].values\n",
    "y_train = traindf[\"target\"].values\n",
    "\n",
    "X_validation = validationdf[\"text\"].values\n",
    "y_validation = validationdf[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_cvec = cvec.fit_transform(X_train, y_train)\n",
    "X_train_tf = tfidf.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timeit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a7264c779f8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This cross validation will only operate on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Start the Timer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timeit' is not defined"
     ]
    }
   ],
   "source": [
    "#=====================Generic 5-fold Cross Validation Score==================\n",
    "# This cross validation will only operate on the training set\n",
    "# Start the Timer\n",
    "start = timeit.default_timer()\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "results_cv = model_selection.cross_val_score(mnb, X_train_cvec, y_train, cv = 5)\n",
    "print(\"Cross validation with countvectorizer: \", results_cv.mean())\n",
    "\n",
    "results_tf = model_selection.cross_val_score(mnb, X_train_tf, y_train, cv = 5)\n",
    "print(\"Cross validation with TfidfVectorizer: \", results_tf.mean())\n",
    "\n",
    "# Timer stops\n",
    "stop = timeit.default_timer()\n",
    "print(\"Time Execution: {}\".format(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the accuracy of a given classifier and vectorizer\n",
    "def nfeature_accuracy_checker(vectorizer=None, n_features=None, stop_words=None, ngram_range=(1, 1), classifier=None):\n",
    "    result = []\n",
    "    print (classifier)\n",
    "    print (\"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        t0 = time()\n",
    "        sentiment_fit = checker_pipeline.fit(X_train, y_train)\n",
    "        y_pred = sentiment_fit.predict(X_validation)\n",
    "        train_test_time = time() - t0\n",
    "        accuracy = accuracy_score(y_pred, y_validation)\n",
    "        print(\"accuracy with\", n, \"features:\", accuracy)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "mnb = MultinomialNB()\n",
    "n_features = np.arange(10000,50001,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_extractor = [None, \"english\"]\n",
    "vectorizer = [cvec, tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================INCLUDING STOP WORDS============================\n",
      "\t=================COUNTVECTORIZER===============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 10000 features: 0.7729375\n",
      "accuracy with 20000 features: 0.773125\n",
      "accuracy with 30000 features: 0.7725625\n",
      "accuracy with 40000 features: 0.7720625\n",
      "accuracy with 50000 features: 0.7723125\n",
      "\n",
      "\n",
      "\t=================TFIDF=============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 10000 features: 0.7689375\n",
      "accuracy with 20000 features: 0.7686875\n",
      "accuracy with 30000 features: 0.7693125\n",
      "accuracy with 40000 features: 0.7684375\n",
      "accuracy with 50000 features: 0.7685625\n",
      "\n",
      "\n",
      "==============================NOT INCLUDING STOP WORDS============================\n",
      "\t=================COUNTVECTORIZER===============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 10000 features: 0.7536875\n",
      "accuracy with 20000 features: 0.7541875\n",
      "accuracy with 30000 features: 0.7549375\n",
      "accuracy with 40000 features: 0.7545625\n",
      "accuracy with 50000 features: 0.7545625\n",
      "\n",
      "\n",
      "\t=================TFIDF=============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 10000 features: 0.7511875\n",
      "accuracy with 20000 features: 0.75225\n",
      "accuracy with 30000 features: 0.754125\n",
      "accuracy with 40000 features: 0.7538125\n",
      "accuracy with 50000 features: 0.753625\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unigram case\n",
    "for i in range(len(stop_word_extractor)):\n",
    "    if i == 0:\n",
    "        print(\"==============================INCLUDING STOP WORDS============================\")\n",
    "    else:\n",
    "        print(\"==============================NOT INCLUDING STOP WORDS============================\")\n",
    "    for j in range(len(vectorizer)):\n",
    "        if j == 0:\n",
    "            print(\"\\t=================COUNTVECTORIZER===============\")\n",
    "        else:\n",
    "            print(\"\\t=================TFIDF=============\")\n",
    "        feature_result_unigram = nfeature_accuracy_checker(vectorizer=vectorizer[j], n_features=n_features, stop_words=stop_word_extractor[i], classifier=mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================INCLUDING STOP WORDS============================\n",
      "\t=================COUNTVECTORIZER===============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 30000 features: 0.791\n",
      "accuracy with 40000 features: 0.791375\n",
      "accuracy with 50000 features: 0.79175\n",
      "accuracy with 60000 features: 0.79075\n",
      "accuracy with 70000 features: 0.7908125\n",
      "accuracy with 80000 features: 0.7911875\n",
      "accuracy with 90000 features: 0.7914375\n",
      "accuracy with 100000 features: 0.79175\n",
      "accuracy with 110000 features: 0.7919375\n",
      "accuracy with 120000 features: 0.792625\n",
      "accuracy with 130000 features: 0.79325\n",
      "\n",
      "\n",
      "\t=================TFIDF=============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 30000 features: 0.7908125\n",
      "accuracy with 40000 features: 0.792375\n",
      "accuracy with 50000 features: 0.7930625\n",
      "accuracy with 60000 features: 0.793\n",
      "accuracy with 70000 features: 0.792625\n",
      "accuracy with 80000 features: 0.7941875\n",
      "accuracy with 90000 features: 0.7948125\n",
      "accuracy with 100000 features: 0.795125\n",
      "accuracy with 110000 features: 0.7945625\n",
      "accuracy with 120000 features: 0.794125\n",
      "accuracy with 130000 features: 0.7948125\n",
      "\n",
      "\n",
      "==============================NOT INCLUDING STOP WORDS============================\n",
      "\t=================COUNTVECTORIZER===============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 30000 features: 0.758625\n",
      "accuracy with 40000 features: 0.7578125\n",
      "accuracy with 50000 features: 0.75975\n",
      "accuracy with 60000 features: 0.7603125\n",
      "accuracy with 70000 features: 0.7609375\n",
      "accuracy with 80000 features: 0.7605625\n",
      "accuracy with 90000 features: 0.7604375\n",
      "accuracy with 100000 features: 0.7605625\n",
      "accuracy with 110000 features: 0.760875\n",
      "accuracy with 120000 features: 0.76075\n",
      "accuracy with 130000 features: 0.76025\n",
      "\n",
      "\n",
      "\t=================TFIDF=============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 30000 features: 0.760875\n",
      "accuracy with 40000 features: 0.7600625\n",
      "accuracy with 50000 features: 0.761875\n",
      "accuracy with 60000 features: 0.761125\n",
      "accuracy with 70000 features: 0.762625\n",
      "accuracy with 80000 features: 0.7625625\n",
      "accuracy with 90000 features: 0.76175\n",
      "accuracy with 100000 features: 0.7618125\n",
      "accuracy with 110000 features: 0.761375\n",
      "accuracy with 120000 features: 0.7620625\n",
      "accuracy with 130000 features: 0.7626875\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bigram case\n",
    "# in here, we modify the number of features from the range 30000 to 130000, since \n",
    "# much more features will be created\n",
    "\n",
    "n_features = np.arange(30000,130001,10000)\n",
    "\n",
    "for i in range(len(stop_word_extractor)):\n",
    "    if i == 0:\n",
    "        print(\"==============================INCLUDING STOP WORDS============================\")\n",
    "    else:\n",
    "        print(\"==============================NOT INCLUDING STOP WORDS============================\")\n",
    "    for j in range(len(vectorizer)):\n",
    "        if j == 0:\n",
    "            print(\"\\t=================COUNTVECTORIZER===============\")\n",
    "        else:\n",
    "            print(\"\\t=================TFIDF=============\")\n",
    "        feature_result_unigram = nfeature_accuracy_checker(vectorizer=vectorizer[j], n_features=n_features, stop_words=stop_word_extractor[i], ngram_range = (1, 2), classifier=mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================INCLUDING STOP WORDS============================\n",
      "\t=================COUNTVECTORIZER===============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 60000 features: 0.7889375\n",
      "accuracy with 70000 features: 0.79\n",
      "accuracy with 80000 features: 0.7894375\n",
      "accuracy with 90000 features: 0.7888125\n",
      "accuracy with 100000 features: 0.788875\n",
      "accuracy with 110000 features: 0.7881875\n",
      "accuracy with 120000 features: 0.7885\n",
      "accuracy with 130000 features: 0.788375\n",
      "accuracy with 140000 features: 0.78825\n",
      "accuracy with 150000 features: 0.789375\n",
      "accuracy with 160000 features: 0.7894375\n",
      "\n",
      "\n",
      "\t=================TFIDF=============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 60000 features: 0.7885625\n",
      "accuracy with 70000 features: 0.7905625\n",
      "accuracy with 80000 features: 0.78975\n",
      "accuracy with 90000 features: 0.79\n",
      "accuracy with 100000 features: 0.7905625\n",
      "accuracy with 110000 features: 0.79\n",
      "accuracy with 120000 features: 0.7896875\n",
      "accuracy with 130000 features: 0.7905625\n",
      "accuracy with 140000 features: 0.7916875\n",
      "accuracy with 150000 features: 0.7914375\n",
      "accuracy with 160000 features: 0.7928125\n",
      "\n",
      "\n",
      "==============================NOT INCLUDING STOP WORDS============================\n",
      "\t=================COUNTVECTORIZER===============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 60000 features: 0.7588125\n",
      "accuracy with 70000 features: 0.76\n",
      "accuracy with 80000 features: 0.7598125\n",
      "accuracy with 90000 features: 0.7601875\n",
      "accuracy with 100000 features: 0.76\n",
      "accuracy with 110000 features: 0.7605\n",
      "accuracy with 120000 features: 0.760375\n",
      "accuracy with 130000 features: 0.759875\n",
      "accuracy with 140000 features: 0.760625\n",
      "accuracy with 150000 features: 0.760625\n",
      "accuracy with 160000 features: 0.7606875\n",
      "\n",
      "\n",
      "\t=================TFIDF=============\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "accuracy with 60000 features: 0.76125\n",
      "accuracy with 70000 features: 0.76275\n",
      "accuracy with 80000 features: 0.7623125\n",
      "accuracy with 90000 features: 0.7629375\n",
      "accuracy with 100000 features: 0.7630625\n",
      "accuracy with 110000 features: 0.7631875\n",
      "accuracy with 120000 features: 0.763625\n",
      "accuracy with 130000 features: 0.764375\n",
      "accuracy with 140000 features: 0.76425\n",
      "accuracy with 150000 features: 0.7644375\n",
      "accuracy with 160000 features: 0.7649375\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trigram case\n",
    "# We furthur extent the number of features to the range of 120000\n",
    "\n",
    "n_features = np.arange(60000,160001,10000)\n",
    "\n",
    "for i in range(len(stop_word_extractor)):\n",
    "    if i == 0:\n",
    "        print(\"==============================INCLUDING STOP WORDS============================\")\n",
    "    else:\n",
    "        print(\"==============================NOT INCLUDING STOP WORDS============================\")\n",
    "    for j in range(len(vectorizer)):\n",
    "        if j == 0:\n",
    "            print(\"\\t=================COUNTVECTORIZER===============\")\n",
    "        else:\n",
    "            print(\"\\t=================TFIDF=============\")\n",
    "        feature_result_unigram = nfeature_accuracy_checker(vectorizer=vectorizer[j], n_features=n_features, stop_words=stop_word_extractor[i], ngram_range = (1, 3), classifier=mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stem_analyzer(document):\n",
    "    return (stemmer.stem(w) for w in analyzer(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing through the analyzer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def lemm_analyzer(document):\n",
    "    return (lemmatizer.lemmatize(w) for w in analyzer(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbGV = MultinomialNB()\n",
    "\n",
    "\n",
    "tvecGV = TfidfVectorizer(ngram_range = (1, 2), max_features = 100000)\n",
    "# tvecGV = TfidfVectorizer(ngram_range = (1, 2), max_features = 100000, stop_words = \"english\")\n",
    "# tvecGV = TfidfVectorizer(ngram_range = (1, 2), max_features = 100000, analyzer = lemm_analyzer)\n",
    "X_tfidf = tvecGV.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79846, 100000)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.78605065 0.7860256  0.78606317 0.78588783 0.78587531 0.78591288]\n",
      "scores_std [0.00287893 0.00293372 0.00299004 0.00300964 0.00306567 0.00304846]\n",
      "{'alpha': 2.07}\n",
      "Time Execution: 1.3531304229982197\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------GRID SEARCH CROSS VALIDATION------------------------------\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Timer begins\n",
    "start = timeit.default_timer()\n",
    "\n",
    "tuned_parameters = [{'alpha' : [2.05, 2.06, 2.07, 2.1, 2.15, 2.2]}]\n",
    "n_folds = 5\n",
    "\n",
    "grid_search = GridSearchCV(estimator = mnb, param_grid = tuned_parameters, cv = n_folds, refit = False, n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_tfidf, y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "scores_std = grid_search.cv_results_['std_test_score']\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "# Optimal hyperparameter\n",
    "bestAlpha = grid_search.best_params_['alpha']\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Timer stops\n",
    "stop = timeit.default_timer()\n",
    "print(\"Time Execution: {}\".format(stop - start))\n",
    "# #-----------------------------END OF GRID SEARCH-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultinomialNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e455c89fe07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnbFinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvecGV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultinomialNB' is not defined"
     ]
    }
   ],
   "source": [
    "mnbFinal = MultinomialNB(alpha = 2.2)\n",
    "X_final = tvecGV.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnbFinal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c7909646d112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnbFinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mnbFinal' is not defined"
     ]
    }
   ],
   "source": [
    "mnbFinal.fit(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mnbFinal.predict(X_final)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7838839991054993\n",
      "Time Execution bagging classifier: 53.636927380997804\n"
     ]
    }
   ],
   "source": [
    "#====================Bagging Classifier with NB Model================\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Timer begins\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Re-create the multinomialNB model, this time using the optimized parameter\n",
    "# that was found through the GridSearchCV\n",
    "mnb = MultinomialNB(alpha = 2.1)\n",
    "\n",
    "bg = BaggingClassifier(mnb, max_samples = 0.6, max_features = 0.5, n_estimators = 200)\n",
    "results = model_selection.cross_val_score(bg, X_tfidf, y_train, cv = 5)\n",
    "print(results.mean())\n",
    "\n",
    "# Timer stops\n",
    "stop = timeit.default_timer()\n",
    "print(\"Time Execution bagging classifier: {}\".format(stop - start))\n",
    "#=============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================TESTING SECTION========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pre = pd.read_csv('testdata.manual.2009.06.14.csv', header = None)\n",
    "\n",
    "clean_test = []\n",
    "\n",
    "for i in range(0, 498):\n",
    "    clean_test.append(clean(df_test_pre[5][i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv file\n",
    "tweet_test = pd.DataFrame(clean_test, columns=['text'])\n",
    "tweet_test['target'] = df_test_pre[0]   # sentiment\n",
    "\n",
    "tweet_test.to_csv('tweet_clean_test.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"tweet_clean_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i loovvee my kindle2. not that the dx is cool...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>reading my kindle2...  love it... lee childs i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ok, first assesment of the  kindle2  ...it fuc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>you'll love your kindle2. i've had mine for a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>fair enough. but i have the kindle2 and i th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>after using latex a lot, any other typeset mat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>494</td>\n",
       "      <td>on that note, i hate word. i hate pages. i hat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>ahh... back in a *real* text editing environme...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>trouble in iran, i see. hmm. iran. iran so far...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "      <td>reading the tweets coming out of iran... the w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               text  target\n",
       "0             0   i loovvee my kindle2. not that the dx is cool...       4\n",
       "1             1  reading my kindle2...  love it... lee childs i...       4\n",
       "2             2  ok, first assesment of the  kindle2  ...it fuc...       4\n",
       "3             3   you'll love your kindle2. i've had mine for a...       4\n",
       "4             4    fair enough. but i have the kindle2 and i th...       4\n",
       "..          ...                                                ...     ...\n",
       "492         492  after using latex a lot, any other typeset mat...       4\n",
       "494         494  on that note, i hate word. i hate pages. i hat...       0\n",
       "495         495  ahh... back in a *real* text editing environme...       4\n",
       "496         496  trouble in iran, i see. hmm. iran. iran so far...       0\n",
       "497         497  reading the tweets coming out of iran... the w...       0\n",
       "\n",
       "[359 rows x 3 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cols = ['sentiment','id','date','query_string','user','text']\n",
    "\n",
    "\n",
    "# drop rows with neutral sentiment \n",
    "df_test.drop(df_test[df_test.target == 2].index, inplace=True)\n",
    "# drop rows with retweet text \n",
    "# df_test.drop(df_test[df_test[5].str.contains(' RT ')].index, inplace=True)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['text']\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test = tvecGV.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=MultinomialNB(alpha=2.1, class_prior=None,\n",
       "                                               fit_prior=True),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "                  max_samples=0.6, n_estimators=200, n_jobs=None,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg.fit(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = bg.predict(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8217270194986073"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
